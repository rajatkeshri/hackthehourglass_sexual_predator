{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xml = \"train/pan12-sexual-predator-identification-training-corpus-2012-05-01.xml\"\n",
    "\n",
    "predator_txt_train = \"train/pan12-sexual-predator-identification-training-corpus-predators-2012-05-01.txt\"\n",
    "predator_txt_1 = \"train/pan12-sexual-predator-identification-diff.txt\"\n",
    "\n",
    "test_xml = \"test/pan12-sexual-predator-identification-test-corpus-2012-05-17.xml\"\n",
    "predator_txt_test = \"train/pan12-sexual-predator-identification-training-corpus-predators-2012-05-01.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN DATA\n",
    "# Parsing the XML file and getting the training data\\n\",\n",
    "tree = ET.parse(train_xml)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Extracting the data and converting to dataframe from XML\n",
    "convo_id_csv = []\n",
    "author_id_csv = []\n",
    "text_csv = []\n",
    "time_csv = []\n",
    "s = []\n",
    "\n",
    "c = 0\n",
    "for convo in root:\n",
    "    convo_id = convo.attrib['id']\n",
    "    for msg in convo:\n",
    "        author_id = msg[0].text\n",
    "        time = msg[1].text\n",
    "        text = msg[2].text\n",
    "\n",
    "        convo_id_csv.append(convo_id)\n",
    "        author_id_csv.append(author_id)\n",
    "        text_csv.append(text)\n",
    "        time_csv.append(time)\n",
    "        s.append(0)\n",
    "\n",
    "    c+=1\n",
    "    \n",
    "csv_dic = {\n",
    "    \"conversation id\": convo_id_csv,\n",
    "    \"author id\": author_id_csv,\n",
    "    \"msg\" : text_csv,\n",
    "    \"time\":time_csv,\n",
    "    \"predator\": s\n",
    "}\n",
    "\n",
    "\n",
    "df_initial = pd.DataFrame.from_dict(csv_dic)\n",
    "df_initial.head()\n",
    "\n",
    "########################################################\n",
    "\n",
    "# Predator messages segration\n",
    "temp_array = []\n",
    "\n",
    "f = open(predator_txt_train, \"r\")\n",
    "predator_ids = f.readlines()\n",
    "f.close()\n",
    "\n",
    "for i in predator_ids:\n",
    "    #print(i.split(\"\\n\")[0])\n",
    "    temp_array.append(i.split(\"\\n\")[0])\n",
    "predator_ids = temp_array\n",
    "\n",
    "f = open(predator_txt_1, \"r\")\n",
    "predator_ids_1 = f.readlines()\n",
    "f.close()\n",
    "\n",
    "for i in predator_ids_1:\n",
    "    #print(i.split(\"\\t\")[0])\n",
    "    temp_array.append(i.split(\"\\t\")[0])\n",
    "predator_ids_1 = temp_array\n",
    "\n",
    "####################################################\n",
    "\n",
    "\n",
    "# updating predator as 1 in csv\n",
    "for i in range(0,len(author_id_csv)):\n",
    "    if (author_id_csv[i] in predator_ids):\n",
    "        s[i] = 1\n",
    "        \n",
    "\n",
    "csv_dic = {\n",
    "    \"conversation id\": convo_id_csv,\n",
    "    \"author id\": author_id_csv,\n",
    "    \"msg\" : text_csv,\n",
    "    \"time\":time_csv,\n",
    "    \"predator\": s\n",
    "}\n",
    "\n",
    "\n",
    "df_predator_update = pd.DataFrame.from_dict(csv_dic)\n",
    "\n",
    "# Removing rows which have null msg\n",
    "df_predator_update[\"msg\"].fillna(value=\"hello\", inplace=True)\n",
    "\n",
    "#################################################\n",
    "\n",
    "# 900000+ rows\n",
    "df_predator_update.to_csv('train_csv.csv')\n",
    "#df_predator_update.to_excel('train.xlsx', engine='xlsxwriter')  \n",
    "\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST DATA\n",
    "# Parsing the XML file and getting the training data\\n\",\n",
    "tree = ET.parse(test_xml)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Extracting the data and converting to dataframe from XML\n",
    "convo_id_csv = []\n",
    "author_id_csv = []\n",
    "text_csv = []\n",
    "time_csv = []\n",
    "s = []\n",
    "\n",
    "c = 0\n",
    "for convo in root:\n",
    "    convo_id = convo.attrib['id']\n",
    "    for msg in convo:\n",
    "        author_id = msg[0].text\n",
    "        time = msg[1].text\n",
    "        text = msg[2].text\n",
    "\n",
    "        convo_id_csv.append(convo_id)\n",
    "        author_id_csv.append(author_id)\n",
    "        text_csv.append(text)\n",
    "        time_csv.append(time)\n",
    "        s.append(0)\n",
    "\n",
    "    c+=1\n",
    "    \n",
    "csv_dic = {\n",
    "    \"conversation id\": convo_id_csv,\n",
    "    \"author id\": author_id_csv,\n",
    "    \"msg\" : text_csv,\n",
    "    \"time\":time_csv,\n",
    "    \"predator\": s\n",
    "}\n",
    "\n",
    "\n",
    "df_initial = pd.DataFrame.from_dict(csv_dic)\n",
    "df_initial.head()\n",
    "\n",
    "########################################################\n",
    "\n",
    "# Predator messages segration\n",
    "temp_array = []\n",
    "\n",
    "f = open(predator_txt_test, \"r\")\n",
    "predator_ids = f.readlines()\n",
    "f.close()\n",
    "\n",
    "for i in predator_ids:\n",
    "    #print(i.split(\"\\n\")[0])\n",
    "    temp_array.append(i.split(\"\\n\")[0])\n",
    "predator_ids = temp_array\n",
    "\n",
    "####################################################\n",
    "\n",
    "\n",
    "# updating predator as 1 in csv\n",
    "for i in range(0,len(author_id_csv)):\n",
    "    if (author_id_csv[i] in predator_ids):\n",
    "        s[i] = 1\n",
    "        \n",
    "\n",
    "csv_dic = {\n",
    "    \"conversation id\": convo_id_csv,\n",
    "    \"author id\": author_id_csv,\n",
    "    \"msg\" : text_csv,\n",
    "    \"time\":time_csv,\n",
    "    \"predator\": s\n",
    "}\n",
    "\n",
    "\n",
    "df_predator_update = pd.DataFrame.from_dict(csv_dic)\n",
    "\n",
    "# Removing rows which have null msg\n",
    "df_predator_update[\"msg\"].fillna(value=\"hello\", inplace=True)\n",
    "\n",
    "#################################################\n",
    "\n",
    "# 900000+ rows\n",
    "df_predator_update.to_csv('test_csv.csv')\n",
    "\n",
    "\n",
    "       \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "import pandas as pd\n",
    "df_all = pd.read_csv('train_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 903604 entries, 0 to 903603\n",
      "Data columns (total 6 columns):\n",
      "Unnamed: 0         903604 non-null int64\n",
      "conversation id    903604 non-null object\n",
      "author id          903604 non-null object\n",
      "msg                903604 non-null object\n",
      "time               903604 non-null object\n",
      "predator           903604 non-null int64\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 41.4+ MB\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-967f79e483a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdf_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mdf_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'conversation id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdf_url\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'conversation id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1143\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0murls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_url\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'msg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1143\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_url' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def find_url(string): \n",
    "    # findall() has been used  \n",
    "    # with valid conditions for urls in string \n",
    "    regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "    url = re.findall(regex,string)       \n",
    "    return [x[0] for x in url] \n",
    "\n",
    "###############################################################\n",
    "# droppin na values\n",
    "df_all.dropna(subset = ['msg'], inplace = True)\n",
    "df_all.index = range(0, df_all.shape[0])\n",
    "df_all.info()\n",
    "\n",
    "# extracting url and replacing it with the word url\n",
    "df_url = df_all[df_all['chat_message'].str.contains(r'https')]\n",
    "#df_url.index = range(0, df_url.shape[0])\n",
    "\n",
    "df_all[df_all['conversation id'] == df_url['conversation id'][1143]]\n",
    "urls = find_url(df_url['msg'][1143])\n",
    "\n",
    "re.sub(regex, 'url', df_url['msg'][903259])\n",
    "df_url['msg'] = df_url['msg'].apply(lambda x: re.sub(regex, 'url', x))\n",
    "df_all['msg'][243] = df_url['msg'][243]\n",
    "for ind in list(df_url.index):\n",
    "    df_all['msg'][ind] = df_url['msg'][ind]\n",
    "\n",
    "print(df)\n",
    "#df_all.to_csv('train_nourl.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
